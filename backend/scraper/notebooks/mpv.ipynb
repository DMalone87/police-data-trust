{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Mapping Police Violence (MPV) Data Into the NPDC Index\n",
    "\n",
    "This notebook loads the [Mapping Police Violence](https://mappingpoliceviolence.org) dataset into the app. \n",
    "\n",
    "Run this whenever the dataset changes to pull in the latest data. Existing rows are ignored.  \n",
    "\n",
    "## Setup\n",
    "\n",
    "Install project dependencies and Jupyter:\n",
    "\n",
    "```bash\n",
    "pip3 install jupyter\n",
    "pip3 install -r requirements/dev_unix.txt\n",
    "```\n",
    "\n",
    "The database should be running and the tables should be up to date. You can use docker to reset the application to a clean state: \n",
    "\n",
    "```bash\n",
    "# Stop services and remove volumes, rebuild images, start the database, create tables, run seeds, and follow logs\n",
    "docker-compose down -v && docker-compose up --build -d db api && docker-compose logs -f\n",
    "```\n",
    "\n",
    "Then open the notebook with either [VSCode](https://code.visualstudio.com/) or `jupyter notebook`.\n",
    "\n",
    "You can run the notebook from the command line as well:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --to notebook --execute backend/scraper/mpv.ipynb --output mpv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T20:04:52.091244Z",
     "iopub.status.busy": "2021-11-15T20:04:52.090739Z",
     "iopub.status.idle": "2021-11-15T20:04:52.684721Z",
     "shell.execute_reply": "2021-11-15T20:04:52.684948Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask_sqlalchemy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/61/vyrh83kx4bl1dwwn53hmt5r00000gn/T/ipykernel_1917/255692896.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflask_sqlalchemy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSQLAlchemy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzip_longest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask_sqlalchemy'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if os.getcwd().endswith(\"scraper\"):\n",
    "    # Run this notebook from the repo root\n",
    "    os.chdir(\"../..\")\n",
    "import sys\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import psycopg2\n",
    "from itertools import zip_longest\n",
    "from typing import List\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "from collections import namedtuple\n",
    "from backend.database import db, Incident, Officer, Accusation, Victim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T20:04:52.688209Z",
     "iopub.status.busy": "2021-11-15T20:04:52.687929Z",
     "iopub.status.idle": "2021-11-15T20:04:52.787715Z",
     "shell.execute_reply": "2021-11-15T20:04:52.787455Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'flask_mail'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/61/vyrh83kx4bl1dwwn53hmt5r00000gn/T/ipykernel_1917/4059661972.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_app\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mapp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"development\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/police-data-trust/backend/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFlaskClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mflask_mail\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mflask_cors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config_from_env\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flask_mail'"
     ]
    }
   ],
   "source": [
    "from backend.api import create_app\n",
    "app = create_app(\"development\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary\n",
    "\n",
    "- Detailed victim information, incident location, and department responsible\n",
    "- Victim-oriented records; MPV ID's identify victims, and incidents are implied\n",
    "- Low (20%) number of incidents with named officers\n",
    "- Reference WaPo and Fatal Encounters ID's. We have no object to model this now but we can update scraper when appropriate\n",
    "- Findings are less precise than CPDP data. CPDP contains investigation records per-accused officer, while MPV gives a single status for the whole incident. Should we model them differently?\n",
    "\n",
    "So, each MPV record will create 1 victim and 1 incident, and some records will also create officers. We will assume victims are 1-1 with incidents, so that we can use the MPV ID for the source ID of the incident, and unambiguously store the vistims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/61/vyrh83kx4bl1dwwn53hmt5r00000gn/T/ipykernel_31828/402781999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# not os.path.exists(dataset_path):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://docs.google.com/spreadsheets/d/1g7CNEDnjk5dH412wmVTAG6XtgWyS2Vax10-BbfsBp0U/export?format=csv\"\n",
    "dataset_path = \"backend/scraper/mpv.csv\"\n",
    "\n",
    "# TODO: Fetch if the file updated. can do with head requests and headers\n",
    "if True:  # not os.path.exists(dataset_path):\n",
    "    print(\"Downloading dataset\")\n",
    "    r = requests.get(dataset_url, stream=True)\n",
    "    with open(dataset_path, \"wb\") as fd:\n",
    "        for chunk in r.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)\n",
    "else:\n",
    "    print(\"Using existing dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_id', 'victim_name', 'victim_gender', 'victim_race',\n",
      "       'victim_age', 'victim_image_url', 'manner_of_injury', 'incident_date',\n",
      "       'address', 'city', 'state', 'zip', 'county', 'latitude', 'longitude',\n",
      "       'description', 'officer_outcomes', 'department', 'criminal_charges',\n",
      "       'source_link', 'off_duty_killing', 'encounter_type_draft',\n",
      "       'encounter_reason_draft', 'officer_names_draft', 'officer_races_draft',\n",
      "       'officer_known_past_shootings_draft', 'call_for_service_draft'],\n",
      "      dtype='object')\n",
      "source_id                                     object\n",
      "victim_name                                   object\n",
      "victim_gender                                 object\n",
      "victim_race                                   object\n",
      "victim_age                                    object\n",
      "victim_image_url                              object\n",
      "manner_of_injury                              object\n",
      "incident_date                         datetime64[ns]\n",
      "address                                       object\n",
      "city                                          object\n",
      "state                                         object\n",
      "zip                                           object\n",
      "county                                        object\n",
      "latitude                                     float64\n",
      "longitude                                    float64\n",
      "description                                   object\n",
      "officer_outcomes                              object\n",
      "department                                    object\n",
      "criminal_charges                              object\n",
      "source_link                                   object\n",
      "off_duty_killing                              object\n",
      "encounter_type_draft                          object\n",
      "encounter_reason_draft                        object\n",
      "officer_names_draft                           object\n",
      "officer_races_draft                           object\n",
      "officer_known_past_shootings_draft            object\n",
      "call_for_service_draft                        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def map_cols(df, m: dict):\n",
    "    return df[list(m.keys())].rename(columns=m)\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(dataset_path, dtype={\"Zipcode\": str, \"MPV ID\": str}, skiprows=1)\n",
    "dataset = map_cols(\n",
    "    dataset,\n",
    "    {\n",
    "        \"MPV ID\": \"source_id\",\n",
    "        \"Victim's name\": \"victim_name\",\n",
    "        \"Victim's gender\": \"victim_gender\",\n",
    "        \"Victim's race\": \"victim_race\",\n",
    "        \"Victim's age\": \"victim_age\",\n",
    "        \"URL of image of victim\": \"victim_image_url\",\n",
    "        \"Cause of death\": \"manner_of_injury\",\n",
    "        \"Date of Incident (month/day/year)\": \"incident_date\",\n",
    "        \"Street Address of Incident\": \"address\",\n",
    "        \"City\": \"city\",\n",
    "        \"State\": \"state\",\n",
    "        \"Zipcode\": \"zip\",\n",
    "        \"County\": \"county\",\n",
    "        \"Latitude\": \"latitude\",\n",
    "        \"Longitude\": \"longitude\",\n",
    "        \"A brief description of the circumstances surrounding the death\": \"description\",\n",
    "        \"Official disposition of death (justified or other), updated on 11/7/2021\": \"officer_outcomes\",\n",
    "        \"Agency responsible for death\": \"department\",\n",
    "        \"Criminal Charges?\": \"criminal_charges\",\n",
    "        \"Link to news article or photo of official document\": \"source_link\",\n",
    "        \"Off-Duty Killing?\": \"off_duty_killing\",\n",
    "        \"Encounter Type (DRAFT)\": \"encounter_type_draft\",\n",
    "        \"Initial Reported Reason for Encounter (DRAFT)\": \"encounter_reason_draft\",\n",
    "        \"Names of Officers Involved (DRAFT)\": \"officer_names_draft\",\n",
    "        \"Race of Officers Involved (DRAFT)\": \"officer_races_draft\",\n",
    "        \"Known Past Shootings of Officer(s) (DRAFT)\": \"officer_known_past_shootings_draft\",\n",
    "        \"Call for Service? (DRAFT)\": \"call_for_service_draft\",\n",
    "    },\n",
    ").set_index(\"source_id\", drop=False)\n",
    "# Some rows are repeated, some ID's seem to be reused.\n",
    "dataset = dataset[~dataset.index.duplicated(keep='first')]\n",
    "assert not dataset.index.has_duplicates\n",
    "\n",
    "print(dataset.columns)\n",
    "print(dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bulk(instances, chunk_size=1000):\n",
    "    \"\"\"Inserts ORM instances into the database\"\"\"\n",
    "    with app.app_context():\n",
    "        for chunk in range(0, len(instances), chunk_size):\n",
    "            db.session.add_all(instances[chunk : chunk + chunk_size])\n",
    "            db.session.flush()\n",
    "        db.session.commit()\n",
    "\n",
    "\n",
    "def isnan(x):\n",
    "    return isinstance(x, float) and math.isnan(x)\n",
    "\n",
    "\n",
    "def nan_to_none(x):\n",
    "    return None if isnan(x) else x\n",
    "\n",
    "\n",
    "def strip_nan(r):\n",
    "    return r._make([nan_to_none(e) for e in r])\n",
    "\n",
    "\n",
    "def map_df(df, mapper):\n",
    "    return [mapper(strip_nan(r)) for r in df.itertuples(index=False)]\n",
    "\n",
    "\n",
    "def parse_int(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def location(r: namedtuple):\n",
    "    return \" \".join(filter(None, [r.address, r.city, r.state, r.zip]))\n",
    "\n",
    "\n",
    "def parse_parts(s: str):\n",
    "    return list(map(lambda x: x.strip(), s.split(\",\"))) if s else []\n",
    "\n",
    "\n",
    "def parse_officers(r: namedtuple):\n",
    "    names = parse_parts(r.officer_names_draft)\n",
    "    races = parse_parts(r.officer_races_draft)\n",
    "\n",
    "    return [\n",
    "        Officer(last_name=name, race=race)\n",
    "        for name, race in zip_longest(names, races)\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse_accusations(r: namedtuple, officers: List[Officer]):\n",
    "    outcomes = parse_parts(r.officer_outcomes)\n",
    "    return [\n",
    "        Accusation(outcome=outcome, officer=officer)\n",
    "        for officer, outcome in zip_longest(officers, outcomes)\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_orm(r: namedtuple):\n",
    "    victim = Victim(\n",
    "        name=r.victim_name,\n",
    "        race=r.victim_race,\n",
    "        gender=r.victim_gender,\n",
    "        manner_of_injury=r.manner_of_injury,\n",
    "        deceased=True,\n",
    "    )\n",
    "    officers = parse_officers(r)\n",
    "    accusations = parse_accusations(r, officers)\n",
    "    incident = Incident(\n",
    "        source_id=r.source_id,\n",
    "        source=\"mpv\",\n",
    "        time_of_incident=r.incident_date,\n",
    "        location=location(r),\n",
    "        description=r.description,\n",
    "        department=r.department,\n",
    "        # latitude=r.latitude,\n",
    "        # longitude=r.longitude,\n",
    "        victims=[victim],\n",
    "        officers=officers,\n",
    "        accusations=accusations,\n",
    "    )\n",
    "    return incident\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9689 existing records. Creating 0 new incidents\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    existing_source_ids = list(\n",
    "        s\n",
    "        for (s,) in db.session.query(Incident.source_id).filter(\n",
    "            Incident.source == \"mpv\", Incident.source_id != None\n",
    "        )\n",
    "    )\n",
    "\n",
    "new_data = dataset.drop(existing_source_ids)\n",
    "incidents = map_df(new_data, create_orm)\n",
    "print(f\"Found {len(existing_source_ids)} existing records. Creating {len(incidents)} new incidents\")\n",
    "create_bulk(incidents)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
